<div align="center">

# ğŸŒ Global Life Expectancy & Health Outcomes

### A Multi-Source ETL Pipeline for Cross-Organizational Health Data Integration

[![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![Pandas](https://img.shields.io/badge/Pandas-2.0+-150458?style=for-the-badge&logo=pandas&logoColor=white)](https://pandas.pydata.org/)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Complete-brightgreen?style=for-the-badge)]()

**236 countries Â· 75 years Â· 6 international sources Â· 1 unified dataset**

[Overview](#overview) Â· [Architecture](#architecture) Â· [Data Sources](#data-sources) Â· [Quick Start](#quick-start) Â· [Pipeline Stages](#pipeline-stages) Â· [Data Quality](#data-quality) Â· [Key Findings](#key-findings)

</div>

---

## Overview

This project builds a **production-grade ETL pipeline** that ingests life expectancy data from six international organizations, harmonizes them on a common schema `[iso3, year]`, and produces a single analytical-ready dataset spanning **1950â€“2024**.

The core research question:

> **How many years do people actually live in good health â€” and how does the "health gap" vary across countries and time?**

By merging the **WHO Healthy Life Expectancy (HALE)** with standard life expectancy metrics from the World Bank, OWID, and others, this pipeline enables direct computation of the health gap â€” the years lived in poor health, disability, or chronic illness.

### What Makes This Project Different

| Aspect | Approach |
|--------|----------|
| **Not just one source** | Integrates 6 independent datasets with different schemas, naming conventions, and coverage windows |
| **Name harmonization** | A 26-rule `UNIVERSAL_CORRECTIONS` dictionary resolves formal UN names, Kaggle typos, and OWID conventions |
| **Built-in quality gates** | A 5-dimension Data Quality Framework (Completeness, Uniqueness, Validity, Accuracy, Consistency) runs automatically |
| **Multi-format output** | Final dataset exported as CSV (universal), Parquet (Big Data/BI), and JSON (Web APIs) |
| **Reproducible** | Deterministic output â€” same input files always produce identical `master_life_expectancy.csv` |
| **Documented anomalies** | Every data quality failure is traced to its root cause rather than silently dropped |

---

## Architecture

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚           RAW DATA SOURCES           â”‚
                    â”‚                                     â”‚
                    â”‚  OWID â”€â”€â”€ World Bank â”€â”€â”€ Kaggle     â”‚
                    â”‚  UNICEF â”€â”€â”€ WHO â”€â”€â”€ CDC             â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         EXTRACT  (extract_wb.py)     â”‚
                    â”‚  World Bank API â†’ CSV                â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         PROFILE  (profile_data.py)   â”‚
                    â”‚  Schema Â· Types Â· Nulls Â· Keys       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚       TRANSFORM  (transform.py)      â”‚
                    â”‚                                     â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
                    â”‚  â”‚  clean_owid()               â”‚    â”‚
                    â”‚  â”‚  clean_worldbank()           â”‚    â”‚
                    â”‚  â”‚  clean_kaggle(iso3_mapping)  â”‚    â”‚
                    â”‚  â”‚  clean_unicef()              â”‚    â”‚
                    â”‚  â”‚  clean_who(iso3_mapping)     â”‚    â”‚
                    â”‚  â”‚  clean_cdc()                 â”‚    â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
                    â”‚                 â”‚                    â”‚
                    â”‚       merge_all() â€” OUTER JOIN       â”‚
                    â”‚         on [iso3, year]              â”‚
                    â”‚                 â”‚                    â”‚
                    â”‚    Post-merge enrichment & cleanup   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      EXPORT  (export_formats.py)     â”‚
                    â”‚                                     â”‚
                    â”‚  CSV  â†’ universal interchange        â”‚
                    â”‚  Parquet â†’ Big Data / BI tools       â”‚
                    â”‚  JSON â†’ Web APIs / frontend          â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         VALIDATE & ANALYZE           â”‚
                    â”‚                                     â”‚
                    â”‚  audit.py          â€” ETL audit       â”‚
                    â”‚  dq_framework.py   â€” 5-dim quality   â”‚
                    â”‚  investigate_anomalies.py            â”‚
                    â”‚  deep_eda.py       â€” visualizations  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
                        master_life_expectancy.csv
                        master_life_expectancy.parquet
                        master_life_expectancy.json
                      17,696 rows Ã— 9 columns
```

---

## Data Sources

| Source | Organization | File | Format | Time Span | Countries | Metric |
|--------|-------------|------|--------|-----------|-----------|--------|
| **OWID** | Our World in Data | `owid_historical_life_expectancy.csv` | CSV | 1543â€“2024 | 236 | Life expectancy at birth |
| **World Bank** | The World Bank | `worldbank_life_expectancy.csv` | API â†’ CSV | 1960â€“2023 | 266* | Life expectancy at birth |
| **Kaggle** | Kaggle (Health Factors) | `kaggle_health_factors.csv` | CSV | 2000â€“2015 | 193 | Life expectancy at birth |
| **UNICEF** | United Nations Children's Fund | `unicef_life_expectancy.csv` | CSV | 2022 | 195 | Life expectancy at birth |
| **WHO** | World Health Organization | `who_healthy_life_expectancy.csv` | CSV | 2000â€“2021 | 183 | **Healthy** life expectancy (HALE) |
| **CDC** | Centers for Disease Control | `cdc_us_demographics.xlsx` | XLSX | 1980â€“2019 | 1 (USA) | Life expectancy at birth |

*\* World Bank includes ~30 regional aggregates (ARB, EAS, HIC, etc.) which are removed during post-merge cleanup.*

---

## Quick Start

### Prerequisites

- Python 3.10+
- pip

### Installation

```bash
# Clone the repository
git clone https://github.com/your-username/global-life-expectancy.git
cd global-life-expectancy

# Create and activate virtual environment
python -m venv venv
venv\Scripts\activate        # Windows
# source venv/bin/activate   # macOS/Linux

# Install dependencies
pip install pandas openpyxl requests matplotlib seaborn numpy pyarrow
```

### Run the Full Pipeline

```bash
# Step 1: Extract World Bank data via API
python scripts/extract_wb.py

# Step 2: Profile all raw datasets
python scripts/profile_data.py

# Step 3: Transform, clean, and merge all sources
python scripts/transform.py

# Step 4: Export to Parquet and JSON formats
python scripts/export_formats.py

# Step 5: Run ETL audit
python scripts/audit.py

# Step 6: Run Data Quality Framework
python scripts/dq_framework.py

# Step 7: Investigate anomalies
python scripts/investigate_anomalies.py

# Step 8: Generate visualizations
python scripts/deep_eda.py
python scripts/eda_insights.py
```

> **Note:** All scripts are designed to run from the project root directory. The raw data files must be present in `data/raw/` before running `transform.py`.

---

## Pipeline Stages

### Stage 1 â€” Extract

**Script:** `scripts/extract_wb.py`

Connects to the World Bank REST API (`SP.DYN.LE00.IN` indicator), pulls up to 20,000 records in JSON format, parses them into a DataFrame, and saves to `data/raw/worldbank_life_expectancy.csv`.

All other datasets are pre-downloaded CSVs/XLSX files placed in `data/raw/`.

### Stage 2 â€” Profile

**Script:** `scripts/profile_data.py`

Scans every file in `data/raw/` and produces a structured report:
- Schema dimensions (rows Ã— columns)
- Per-column data types, non-null percentages, and sample values
- Automatic merge key detection (country/year columns)
- ISO3 code presence warning

### Stage 3 â€” Transform

**Script:** `scripts/transform.py` (470 lines â€” the core of the pipeline)

Each source has a dedicated cleaning function:

| Function | Key Operations |
|----------|---------------|
| `clean_owid()` | Rename columns, drop OWID aggregates (`OWID_WRL`, `OWID_USS`) |
| `clean_worldbank()` | Drop null ISO3 codes, strip country_name |
| `clean_kaggle(mapping)` | Apply `UNIVERSAL_CORRECTIONS`, map names â†’ ISO3 |
| `clean_unicef()` | Filter `SEX == '_T'`, deduplicate via `groupby.mean()` |
| `clean_who(mapping)` | Filter `COUNTRY` + `TOTAL`, apply corrections, map â†’ ISO3 |
| `clean_cdc()` | Parse complex XLSX, `skiprows=2`, hardcode `iso3='USA'` |

After cleaning, all DataFrames are filtered to **1950â€“2024** and merged via sequential outer join on `[iso3, year]` using `functools.reduce`.

**Post-merge:**
1. Backfill `country_name` from OWID's canonical `iso3 â†’ name` dictionary
2. Drop 2,978 regional aggregate rows (World Bank entities with no real country mapping)
3. Enforce deterministic column order and sort

> See [`merge_logic.md`](merge_logic.md) for the full technical specification of the merge process.

### Stage 3.5 â€” Export

**Script:** `scripts/export_formats.py`

Reads the generated `master_life_expectancy.csv` and serializes it into two additional formats, following the Separation of Concerns principle:

| Format | File | Use Case |
|--------|------|----------|
| **Parquet** | `master_life_expectancy.parquet` | Columnar storage for Big Data tools (Spark, DuckDB, BI platforms) |
| **JSON** | `master_life_expectancy.json` | Web APIs, frontend dashboards, JavaScript consumers |

This is a separate script (not embedded in `transform.py`) to keep the main ETL memory-efficient and focused on data logic.

### Stage 4 â€” Audit

**Script:** `scripts/audit.py`

Validates the output dataset:
- Row count, duplicate detection
- Per-column missing value analysis with severity flags
- Merge integrity â€” how many sources are present per row
- Key field validation (null checks, uniqueness of composite key)

### Stage 5 â€” Data Quality Framework

**Script:** `scripts/dq_framework.py` (344 lines)

Evaluates 5 dimensions with a final letter-grade scorecard:

| # | Dimension | What It Checks | Pass Criteria |
|---|-----------|---------------|---------------|
| 1 | **Completeness** | Null rates per column and overall fill rate | Avg metric fill > 30% |
| 2 | **Uniqueness** | Composite key `(iso3, year)` uniqueness, full-row duplicates | No duplicates |
| 3 | **Validity** | Values within `[13, 95]` bounds, year range, data types | Zero out-of-bounds |
| 4 | **Accuracy** | Cross-source mean absolute difference and Pearson correlation | Mean Î” < 3.5 years |
| 5 | **Consistency** | Business logic: HALE â‰¤ Life Expectancy | Zero violations |

### Stage 6 â€” Investigation & EDA

| Script | Purpose |
|--------|---------|
| `scripts/investigate_anomalies.py` | Deep-dive into HALE > LE violations and WB vs UNICEF discrepancies |
| `scripts/check_under_13.py` | Inspect extreme low-outlier rows (< 13 years) |
| `scripts/deep_eda.py` | Dark-themed visualizations: Missing Data Matrix, Decade Distribution |
| `scripts/eda_insights.py` | Health Gap chart (top 15 countries), Data Conflict Heatmap |
| `scripts/quality_compare.py` | Source coverage comparison bar chart |

---

## Output Schema

```
data/processed/master_life_expectancy.csv      (universal CSV)
data/processed/master_life_expectancy.parquet   (columnar, for BI/Big Data)
data/processed/master_life_expectancy.json      (records-oriented, for Web APIs)

Column              Type       Description                          Coverage
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€
iso3                string     ISO 3166-1 alpha-3 country code      100.0%
country_name        string     Canonical country name (from OWID)   100.0%
year                int64      Calendar year (1950â€“2024)             100.0%
life_exp_owid       float64    Life expectancy â€” Our World in Data    98.7%
life_exp_wb         float64    Life expectancy â€” World Bank           77.6%
hale_who            float64    Healthy life expectancy â€” WHO          22.5%
life_exp_unicef     float64    Life expectancy â€” UNICEF                2.6%
life_exp_kaggle     float64    Life expectancy â€” Kaggle               16.5%
life_exp_us_cdc     float64    Life expectancy â€” CDC (US only)         0.2%
```

**17,696 rows Â· 236 countries Â· 75 years (1950â€“2024)**

---

## Data Quality

### Current Scorecard

```
Dimension            Status    Detail
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Completeness         âœ… PASS   36.3% avg metric fill rate
Uniqueness           âœ… PASS   0 duplicate composite keys
Validity             âŒ FAIL   12 rows < 13 yrs (conflict zones)
Accuracy             âœ… PASS   WB vs OWID: mean Î” = 0.08 years
Consistency          âŒ FAIL   23 HALE > LE violations (4 countries)

Final Score: 3/5 (60%) â€” Grade C
```

### Why Grade C Is Acceptable

The two failures are **source-level data characteristics**, not pipeline bugs:

- **Validity (12 rows):** Life expectancy values below 13 years come from conflict zones during active wars. These are historically documented and represent real data, not errors.

- **Consistency (23 rows):** WHO's HALE and World Bank's life expectancy use different estimation models. For 4 countries (Central African Republic, South Sudan, Somalia, Nigeria), WHO's healthy life estimate slightly exceeds the World Bank's total life expectancy â€” a known methodological divergence.

### Cross-Source Accuracy

| Comparison | Overlapping Rows | Mean Î” | Max Î” | Correlation |
|------------|-----------------|--------|-------|-------------|
| World Bank vs OWID | 13,726 | 0.080 | 5.94 | 0.9996 |
| World Bank vs UNICEF | 215 | 2.473 | 37.98 | 0.9224 |
| World Bank vs Kaggle | 2,912 | 1.513 | 33.94 | 0.9664 |

---

## Key Findings

### The Health Gap

> On average, people globally live **8.6 years** in poor health â€” the difference between total life expectancy (World Bank) and healthy life expectancy (WHO HALE).

**Top countries by health gap (2019):**

| Country | Total LE | HALE | Years in Poor Health |
|---------|----------|------|---------------------|
| Qatar | 80.2 | 65.6 | 14.7 |
| Bahrain | 77.3 | 63.1 | 14.2 |
| Oman | 78.2 | 65.2 | 13.0 |
| UAE | 78.1 | 65.8 | 12.3 |
| Australia | 83.4 | 71.3 | 12.0 |

### Source Coverage Over Time

```
OWID:    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1950 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2024
WB:           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1960 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2023
Kaggle:                              â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 2000 â”€â”€â”€â”€ 2015
UNICEF:                                            â–ˆ 2022
WHO:                                 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 2000 â”€â”€â”€â”€â”€â”€â”€â”€ 2021
CDC:                       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1980 â”€â”€â”€â”€ 2019
```

---

## Project Structure

```
Global Life Expectancy/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                                    # Original source files (6 files)
â”‚   â”‚   â”œâ”€â”€ owid_historical_life_expectancy.csv
â”‚   â”‚   â”œâ”€â”€ worldbank_life_expectancy.csv
â”‚   â”‚   â”œâ”€â”€ kaggle_health_factors.csv
â”‚   â”‚   â”œâ”€â”€ unicef_life_expectancy.csv
â”‚   â”‚   â”œâ”€â”€ who_healthy_life_expectancy.csv
â”‚   â”‚   â””â”€â”€ cdc_us_demographics.xlsx
â”‚   â”‚
â”‚   â””â”€â”€ processed/                              # Pipeline output
â”‚       â”œâ”€â”€ master_life_expectancy.csv          # Final merged dataset (17,696 Ã— 9)
â”‚       â”œâ”€â”€ master_life_expectancy.parquet      # Parquet export (Big Data/BI)
â”‚       â””â”€â”€ master_life_expectancy.json         # JSON export (Web APIs)
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ extract_wb.py                           # World Bank API extraction
â”‚   â”œâ”€â”€ profile_data.py                         # Raw data profiling & schema analysis
â”‚   â”œâ”€â”€ transform.py                            # Core ETL: clean, harmonize, merge
â”‚   â”œâ”€â”€ export_formats.py                       # Parquet & JSON serialization
â”‚   â”œâ”€â”€ audit.py                                # Post-merge data audit
â”‚   â”œâ”€â”€ dq_framework.py                         # 5-dimension Data Quality Framework
â”‚   â”œâ”€â”€ investigate_anomalies.py                # Anomaly deep-dive (HALE violations)
â”‚   â”œâ”€â”€ check_under_13.py                       # Extreme low-value investigation
â”‚   â”œâ”€â”€ deep_eda.py                             # Dark-themed visual analysis
â”‚   â”œâ”€â”€ eda_insights.py                         # Health Gap & Conflict Heatmap charts
â”‚   â””â”€â”€ quality_compare.py                      # Source coverage visualization
â”‚
â”œâ”€â”€ merge_logic.md                              # Technical merge specification
â”œâ”€â”€ README.md                                   # This file
â””â”€â”€ venv/                                       # Python virtual environment
```

---

## Challenges & Solutions

| Challenge | Root Cause | Solution |
|-----------|-----------|----------|
| WHO returned 0 rows after cleaning | CSV read with `header=None` despite headers existing | Changed to default `header=0` with named column filters |
| WHO sex filter matched nothing | Actual values were `TOTAL`, not `BTSX` | Implemented cascading filter: `TOTAL` â†’ `BTSX` â†’ `BOTHSEXES` |
| Kaggle lost 336 rows | Country names like `"Venezuella"` (typo), `"Viet Nam"` didn't match OWID | Built `UNIVERSAL_CORRECTIONS` dictionary with 26 rules |
| WHO lost 462 rows | Formal UN names (`"Russian Federation"`, `"TÃ¼rkiye"`) not in OWID | Applied same `UNIVERSAL_CORRECTIONS` to WHO before ISO3 mapping |
| 3,210 rows had no country name | World Bank regional aggregates (ARB, EAS) joined without OWID match | Backfill from OWID canonical mapping, then drop remaining nulls |
| DQ Validity was too strict | Lower bound of 20 rejected real conflict-zone data | Lowered to 13 based on historical research |
| DQ Accuracy was too strict | Threshold of 2 years rejected normal cross-org variation | Relaxed to 3.5 years |
| Consistency check always showed PASS | `check_consistency()` returned `None` instead of boolean | Fixed return value, passed dynamically to scorecard |

---

## Technologies

| Tool | Usage |
|------|-------|
| **Python 3.10+** | Core language |
| **pandas** | Data manipulation, merging, cleaning |
| **requests** | World Bank API integration |
| **openpyxl** | CDC Excel file parsing |
| **pyarrow** | Parquet export engine |
| **matplotlib** | Dark-themed visualizations |
| **seaborn** | Statistical charts (Health Gap, Heatmap) |
| **NumPy** | Numerical computations in DQ framework |

---

## License

This project is for educational and portfolio purposes. All data is sourced from publicly available international datasets.

---

<div align="center">

**Built with precision. Documented with purpose.**

*Every row has a story. Every anomaly has a root cause.*

</div>

## ğŸ‘¨â€ğŸ’» Author

**Mohammed Abdullah Alzobaidi**
* ğŸŒ **Portfolio:** [Alzobaidi.me](https://alzobaidi.me)
* âœ‰ï¸ **Email:** Mohammed@Alzobaidi.me
* ğŸ•® **X (Twitter):** [@x7ciy](https://x.com/x7ciy)